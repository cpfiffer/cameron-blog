<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,400;0,500;1,400;1,500&display=swap"
            rel="stylesheet"
        />
        <link
            href="https://fonts.googleapis.com/css2?family=Comfortaa:wght@300..700&display=swap"
            rel="stylesheet"
        />
         
        <link rel="stylesheet" href="/libs/highlight/styles/github.min.css">
   <link rel="stylesheet" href="/css/normalize.css" />
<link rel="stylesheet" href="/css/franklin.css" />
<link rel="stylesheet" href="/css/hypertext.css" />
<link rel="icon" href="/assets/favicon.png" />

<!-- Favicon -->
<link
    rel="apple-touch-icon"
    sizes="180x180"
    href="/assets/apple-touch-icon.png"
/>
<link
    rel="icon"
    type="image/png"
    sizes="32x32"
    href="/assets/favicon-32x32.png"
/>
<link
    rel="icon"
    type="image/png"
    sizes="16x16"
    href="/assets/favicon-16x16.png"
/>
<link rel="manifest" href="/assets/site.webmanifest" />
 
        <title>PromptingTools.jl supports Groq</title>
        
    </head>
    <body>
        <div class="center-column-holder">
            <div class="center-column">
                <header>
    <div class="header-nav">
        <span class="site-name">â—¯ <a href="/" class="site-name-link">Cameron</a></span>
        <div>
            <a href="/">home</a> âˆ˜ <a href="/about">about</a> âˆ˜ <a href="/blog/">blog</a> âˆ˜
            <a href="/links/">links</a>
        </div>
    </div>
    <hr />
</header>

                <!-- Content appended here -->
                <button id="theme-toggle" aria-label="Toggle dark mode">
                    ðŸŒ™
                </button>
            </div>
        </div>
        <style>
            #theme-toggle {
                position: fixed;
                top: 1rem;
                right: 1rem;
                padding: 0.5rem;
                font-size: 1.25rem;
                border: none;
                background: none;
                cursor: pointer;
                z-index: 1000;
            }
        </style>
        <script>
            // Check for saved theme preference, otherwise use system preference
            const getPreferredTheme = () => {
                const savedTheme = localStorage.getItem("theme");
                if (savedTheme) {
                    return savedTheme;
                }
                return window.matchMedia("(prefers-color-scheme: dark)").matches
                    ? "dark"
                    : "light";
            };

            // Apply theme
            const setTheme = (theme) => {
                document.documentElement.setAttribute("data-theme", theme);
                localStorage.setItem("theme", theme);
                // Update button text
                document.getElementById("theme-toggle").innerText =
                    theme === "dark" ? "â˜¼" : "â˜¾";
            };

            // Initialize theme
            setTheme(getPreferredTheme());

            // Add toggle functionality
            document
                .getElementById("theme-toggle")
                .addEventListener("click", () => {
                    const currentTheme =
                        document.documentElement.getAttribute("data-theme");
                    setTheme(currentTheme === "dark" ? "light" : "dark");
                });

            // Listen for system theme changes
            window
                .matchMedia("(prefers-color-scheme: dark)")
                .addEventListener("change", (e) => {
                    if (!localStorage.getItem("theme")) {
                        setTheme(e.matches ? "dark" : "light");
                    }
                });
        </script>
    </body>
</html>
<div class="franklin-content">
<h1 id="promptingtoolsjl_supports_groq"><a href="#promptingtoolsjl_supports_groq" class="header-anchor">PromptingTools.jl supports Groq</a></h1>
<p>PromptingTools.jl, one of my favorite Julia packages for generative AI workflows, now supports groq&#33;  For those who do not know, groq is <a href="https://wow.groq.com/groq-sets-new-large-language-model-performance-record-of-300-tokens-per-second-per-user-on-meta-ai-foundational-llm-llama-2-70b/">incredibly fast</a>. Of the cloud providers for LLM generation, groq is by far the fastest.</p>
<p>You&#39;ll need PromptingTools.jl version 0.22. The release notes are <a href="https://github.com/svilupp/PromptingTools.jl/releases/tag/v0.22.0">here</a>.</p>
<p>Here&#39;s a little demo of how to use this. To start, you&#39;ll need a groq API key, which you can find on the website &#40;<a href="https://console.groq.com/keys">this link</a> might work?&#41;.</p>
<p>Put your key in the environment variable <code>GROQ_API_KEY</code>. If you haven&#39;t done this at the system level, you can do it inside Julia like so:</p>
<pre><code class="language-julia">ENV&#91;&quot;GROQ_API_KEY&quot;&#93; &#61; &quot;your_key_here&quot;</code></pre>
<p>Great. Now we can use PromptingTools:</p>
<pre><code class="language-julia">using PromptingTools
using PromptingTools: GroqOpenAISchema


# Create the schema
schema &#61; GroqOpenAISchema&#40;&#41;
some_julia_code &#61; aigenerate&#40;
    schema,
    &quot;&quot;&quot;
    Give me some Julia code to calculate the n-th Fibonacci number.
    &quot;&quot;&quot;,
    model&#61;&quot;gllama370&quot;
&#41;

# Show the result
println&#40;some_julia_code.content&#41;</code></pre>
<p>which yielded &#40;for me&#41; the response</p>
<hr />
<p>Here is an example of Julia code to calculate the n-th Fibonacci number:</p>
<pre><code class="language-julia">function fibonacci&#40;n::Int&#41;
    if n &#61;&#61; 1
        return 0
    elseif n &#61;&#61; 2
        return 1
    else
        a, b &#61; 0, 1
        for i in 3:n
            a, b &#61; b, a &#43; b
        end
        return b
    end
end</code></pre>
<p>This function uses a simple iterative approach to calculate the n-th Fibonacci number. It takes an integer <code>n</code> as input and returns the corresponding Fibonacci number.</p>
<p>Here&#39;s an explanation of how the code works:</p>
<ul>
<li><p>The function takes an integer <code>n</code> as input and returns the n-th Fibonacci number.</p>
</li>
<li><p>The first two Fibonacci numbers are 0 and 1, so we handle these cases explicitly.</p>
</li>
<li><p>For <code>n &gt; 2</code>, we use a loop to calculate the n-th Fibonacci number. We initialize two variables <code>a</code> and <code>b</code> to 0 and 1, respectively, which correspond to the first two Fibonacci numbers.</p>
</li>
<li><p>In each iteration of the loop, we update <code>a</code> and <code>b</code> by swapping their values and adding the previous value of <code>a</code> to <code>b</code>. This is equivalent to calculating the next Fibonacci number as the sum of the previous two.</p>
</li>
<li><p>After <code>n-2</code> iterations, <code>b</code> will contain the n-th Fibonacci number, which we return as the result.</p>
</li>
</ul>
<p>You can test this function with a specific value of <code>n</code>, for example:</p>
<pre><code class="language-julia">julia&gt; fibonacci&#40;10&#41;
55</code></pre>
<hr />
<p>This isn&#39;t <em>quite</em> right. Calling this function with <code>fibonacci&#40;10&#41;</code> yields 34, not 55. This seems to be due to llama3 shifting the function up by one â€“ <code>fibonacci&#40;0&#41;</code> should be 0, but here <code>fibonacci&#40;1&#41;</code> is 0.</p>
<p>But it&#39;s close enough for a prompt&#33;</p>
<p>You can also use string macros to make this a bit more concise:</p>
<pre><code class="language-julia"># Instead, you can also do string macros. You can do this by preceding
# the string with &#96;ai&#96; and following it with the model you want to use.
# In this case, we want to use groq&#39;s Llama3 70b &#40;gllama370&#41; model.
ai&quot;Give me some Julia code to calculate the n-th Fibonacci number.&quot;gllama370</code></pre>
<p>This is in case you&#39;re working from the REPL and don&#39;t want to type out the <code>aigenerate</code> function call.</p>
<p>You can use providers that are not groq as well. All providers available in PromptingTools.jl are available <a href="https://siml.earth/PromptingTools.jl/dev/coverage_of_model_providers">here</a>,  but the list is quite long. Providers include</p>
<ul>
<li><p>OpenAI</p>
</li>
<li><p>vLLM</p>
</li>
<li><p>Ollama</p>
</li>
<li><p>Mistral</p>
</li>
<li><p>Databricks</p>
</li>
<li><p>Fireworks AI</p>
</li>
<li><p>Together AI</p>
</li>
<li><p>Anthropic</p>
</li>
<li><p>Google Gemini</p>
</li>
</ul>
<p>Lastly, if you want to use other model aliases &#40;like <code>gllama370</code>&#41;, you can check them out inside <code>PromptingTools.MODEL_ALIASES</code>:</p>
<pre><code class="language-julia">julia&gt; PromptingTools.MODEL_ALIASES

Dict&#123;String, String&#125; with 38 entries:
  &quot;local&quot;         &#61;&gt; &quot;local-server&quot;
  &quot;gpt4v&quot;         &#61;&gt; &quot;gpt-4-vision-preview&quot;
  &quot;gpt3&quot;          &#61;&gt; &quot;gpt-3.5-turbo&quot;
  &quot;gpt4&quot;          &#61;&gt; &quot;gpt-4&quot;
  &quot;firefunction&quot;  &#61;&gt; &quot;accounts/fireworks/models/firefunction-v1&quot;
  &quot;tllama3&quot;       &#61;&gt; &quot;meta-llama/Llama-3-8b-chat-hf&quot;
  &quot;gpt4t&quot;         &#61;&gt; &quot;gpt-4-turbo&quot;
  &quot;mistral-tiny&quot;  &#61;&gt; &quot;mistral-tiny&quot;
  &quot;mistrall&quot;      &#61;&gt; &quot;mistral-large-latest&quot;
  &quot;emb3small&quot;     &#61;&gt; &quot;text-embedding-3-small&quot;
  &quot;starling&quot;      &#61;&gt; &quot;starling-lm&quot;
  &quot;tllama370&quot;     &#61;&gt; &quot;meta-llama/Llama-3-70b-chat-hf&quot;
  &quot;oh25&quot;          &#61;&gt; &quot;openhermes2.5-mistral&quot;
  &quot;mistral-large&quot; &#61;&gt; &quot;mistral-large-latest&quot;
  &quot;gemini&quot;        &#61;&gt; &quot;gemini-pro&quot;
  &quot;gl3&quot;           &#61;&gt; &quot;llama3-8b-8192&quot;
  &quot;gllama370&quot;     &#61;&gt; &quot;llama3-70b-8192&quot;
  &quot;mistralm&quot;      &#61;&gt; &quot;mistral-medium-latest&quot;
  &quot;tmixtral22&quot;    &#61;&gt; &quot;mistralai/Mixtral-8x22B-Instruct-v0.1&quot;
  &quot;ollama3&quot;       &#61;&gt; &quot;llama3:8b-instruct-q5_K_S&quot;
  â‹®               &#61;&gt; â‹®</code></pre>
<p>Anyways â€“ thanks to <a href="https://siml.earth/">Jan</a> for more incredible work&#33;</p>
<p>â€“ Cameron</p>
</div><!-- CONTENT ENDS HERE -->

</div> <!-- end of center-column -->
</div> <!-- end of center-column-holder -->
    
    
        <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>

    
    
  </body>
</html>
